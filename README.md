周志华《机器学习》集成学习算法实践

项目简介
基于周志华《机器学习》（西瓜书）第8章**集成学习**理论，实现XGBoost、LightGBM梯度提升树算法，以加州房价数据集为案例完成回归任务，对比两种集成学习算法的性能与特征重要性。

核心内容
1. **复现XGBoost梯度提升树**（周志华集成学习进阶算法）  
2. **复现LightGBM直方图优化梯度提升树**  
3. **回归任务性能评估**（MSE/R²）  
4. **特征重要性可视化分析**

环境安装
pip install -r requirements.txt

快速运行
python main.py

运行结果

1. 算法性能对比（回归任务核心指标）
算法          均方误差 (MSE)   决定系数 (R²)   说明
XGBoost       ~0.25            ~0.84           经典梯度提升树，稳定性强

LightGBM      ~0.24            ~0.85           直方图优化，效率更高

**注**：MSE 越小表示预测误差越小，R² 越接近 1 表示模型拟合效果越好（周志华《机器学习》模型评估章节核心指标）。

2. 特征重要性分析图
（见项目输出图表）

3. 完整性能数据
见：performance.txt

核心理论参考
- 周志华《机器学习》第 8 章 集成学习（梯度提升树部分）  
- XGBoost 官方文档：https://xgboost.readthedocs.io/  
- LightGBM 官方文档：https://lightgbm.readthedocs.io/
